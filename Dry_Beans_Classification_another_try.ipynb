{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install catboost optuna","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:05.669487Z","iopub.status.busy":"2021-09-14T08:19:05.668246Z","iopub.status.idle":"2021-09-14T08:19:14.541461Z","shell.execute_reply":"2021-09-14T08:19:14.540503Z","shell.execute_reply.started":"2021-09-14T08:19:05.669394Z"},"id":"syPhAz0tdsj8","outputId":"29e1890b-04db-4d71-a0ac-cf49dcfb4a6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import  SelectKBest\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC,LinearSVC,NuSVC\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport xgboost as xgb\nimport catboost as ctb\nimport lightgbm as gbm\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import sys\n# sys.path.append('../')\n\n# # import basic_preprocessing.ipynb\n# from preprocessing.preprocessing import   *\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, plot_confusion_matrix\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score, f1_score\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:28.744115Z","iopub.status.busy":"2021-09-14T08:19:28.743264Z","iopub.status.idle":"2021-09-14T08:19:31.567873Z","shell.execute_reply":"2021-09-14T08:19:31.567100Z","shell.execute_reply.started":"2021-09-14T08:19:28.744052Z"},"id":"Z3CzgttpdMLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import ADASYN\n\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import boxcox, mode, zscore\n\nimport os\nimport sys\n\n\ndef log_transform(df, cols):\n    for col in cols:\n        df[col] = np.log1p(df[col])\n    return df\n\n\ndef sqrt_transform(df, cols):\n    for col in cols:\n        df[col] = np.sqrt(df[col])\n    return df\n\n\ndef boxcox_transform(df, cols):\n    for col in cols:\n        df[col], _ = boxcox(df[col])\n    return df\n\n\ndef feature_log_transform(df, cols):\n    for col in cols:\n        df[col+\"_log\"] = np.log1p(df[col])\n    return df\n\n\ndef feature_sqrt_transform(df, cols):\n    for col in cols:\n        df[col+'_sqrt'] = np.sqrt(df[col])\n    return df\n\n\ndef feature_boxcox_transform(df, cols):\n    for col in cols:\n        df[col+\"_boxcox\"], _ = boxcox(df[col])\n    return df\n\n\ndef remove_outliers(df, cols):\n    for col in cols:\n        q_low = df[col].quantile(0.01)\n        q_hi = df[col].quantile(0.99)\n        df_filtered = df[(df[col] < q_hi) & (df[col] > q_low)]\n\n    return df_filtered\n\n\ndef remove_outliers_zscore(df):\n    z_scores = zscore(df)\n    # calculate z-scores of `df`\n\n    abs_z_scores = np.abs(z_scores)\n    filtered_entries = (abs_z_scores < 3).all(axis=1)\n    new_df = df[filtered_entries]\n\n    return new_df\n\n\ndef features_target(df, features):\n    X = df[features]\n    y = df['y']\n\n    return X, y\n\n\ndef float_of_column(df, cols):\n    for col in cols:\n        colname = col+\"_float\"\n        intcol = df[col].astype(int)\n        df[colname] = df[col] - intcol\n    return df\n\n# # use smote to upsample impalanced class\n\n\ndef upsample_minority(df, features):\n\n    df_X = df[features]\n    df_y = df['y']\n    sm = SMOTE()\n\n    df_X, df_y = sm.fit_resample(df_X, df_y)\n    df = pd.merge(df_X, df_y, left_index=True, right_index=True)\n\n    return df\n\n\ndef upsample_minority_BorderlineSMOTE(df, features):\n\n    df_X = df[features]\n    df_y = df['y']\n    sm = BorderlineSMOTE()\n\n    df_X, df_y = sm.fit_resample(df_X, df_y)\n    df = pd.merge(df_X, df_y, left_index=True, right_index=True)\n\n    return df\n\n\ndef upsample_minority_ADASYN(df, features):\n\n    df_X = df[features]\n    df_y = df['y']\n    sm = ADASYN()\n\n    df_X, df_y = sm.fit_resample(df_X, df_y)\n    df = pd.merge(df_X, df_y, left_index=True, right_index=True)\n\n    return df\n\n# replace avg with mode\n\n\ndef add_cluster_feature(df, n):\n    labels = np.zeros((df.shape[0], n))\n\n    for i in range(n):\n        km = KMeans(n_clusters=7, random_state=i)\n        km.fit(df)\n        labels[:, i] = km.predict(df)\n\n    final_labels = mode(labels, axis=1)[0]\n    return final_labels\n\n\ndef add_feature_area_minus_convex(df):\n    df['remaining_area'] = np.abs(df['ConvexArea'] - df['Area'])\n    return df\n\n\ndef add_feature_shapeFactor5(df):\n    df['shapeFactor5'] = df['Area'] / \\\n        ((((df['MinorAxisLength'])**2)/4) * np.pi)\n    return df\n\n\ndef add_feature_curl(df):\n    df['fibre_length'] = (\n        df['Perimeter'] - np.sqrt(np.abs(df['Perimeter']**2 - (16*df['Area'])))) / 4\n\n    df['fibre_width'] = df['Area'] / df['fibre_length']\n    df['curl'] = df['MajorAxisLength'] / df['fibre_length']\n\n    return df\n\n\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:32.623289Z","iopub.status.busy":"2021-09-14T08:19:32.623023Z","iopub.status.idle":"2021-09-14T08:19:32.763095Z","shell.execute_reply":"2021-09-14T08:19:32.762383Z","shell.execute_reply.started":"2021-09-14T08:19:32.623265Z"},"id":"otNwWEfeddd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'kaggle' in os.environ.get('KAGGLE_URL_BASE','localhost'):\n    print(\"kaggle\")\n    dataset_path = '../input/dry-beans-classification-iti-ai-pro-intake01/'\n    train = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n    test = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\n\nelse:\n    print(\"localhost\")\n    train = pd.read_csv('train.csv')\n    test = pd.read_csv('test.csv')","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:47.841909Z","iopub.status.busy":"2021-09-14T08:19:47.841630Z","iopub.status.idle":"2021-09-14T08:19:47.966616Z","shell.execute_reply":"2021-09-14T08:19:47.965741Z","shell.execute_reply.started":"2021-09-14T08:19:47.841883Z"},"id":"laEd5AcAdMLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train.columns.delete([0,-1])\nX,y = features_target(train,features)","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:49.214220Z","iopub.status.busy":"2021-09-14T08:19:49.213948Z","iopub.status.idle":"2021-09-14T08:19:49.227951Z","shell.execute_reply":"2021-09-14T08:19:49.227064Z","shell.execute_reply.started":"2021-09-14T08:19:49.214193Z"},"id":"SdCeUc5KdMLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_cols = ['Perimeter','MajorAxisLength','MinorAxisLength','EquivDiameter']\n# skewed_cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n#        'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n#        'Solidity', 'roundness', 'ShapeFactor2',\n#        'ShapeFactor4']\nskewed_cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n       # 'AspectRation', 'Eccentricity',\n        'ConvexArea', \n       # 'EquivDiameter', 'Extent',\n       'Solidity', 'roundness', 'ShapeFactor2',\n       'ShapeFactor4']\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:51.584173Z","iopub.status.busy":"2021-09-14T08:19:51.583840Z","iopub.status.idle":"2021-09-14T08:19:51.589189Z","shell.execute_reply":"2021-09-14T08:19:51.588364Z","shell.execute_reply.started":"2021-09-14T08:19:51.584142Z"},"id":"NIUDxv7zdMLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss = StandardScaler()\nmm= MinMaxScaler()\n# scaled_train = ss.fit_transform(train[features])\n# scaled_test = ss.transform(test[features])\nids = test['ID']\ny = train.y\ntrain = train.drop(['ID','y'], axis=1)\ntest = test.drop(['ID'], axis=1)\n\nss_train = ss.fit_transform(train)\nss_train_df = pd.DataFrame(ss_train,columns=train.columns)\nss_test = ss.transform(test)\nss_test_df = pd.DataFrame(ss_test,columns=test.columns)\n\nmm_train = mm.fit_transform(train)\nmm_train_df = pd.DataFrame(ss_train,columns=train.columns)\nmm_test = mm.transform(test)\nmm_test_df = pd.DataFrame(ss_test,columns=test.columns)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef pipline_train(df):\n    # df = float_of_column(df,float_cols)\n\n    # df = remove_outliers(df,list(features))\n#     df = upsample_minority(df,features)\n\n    # # X,y = features_target(df,features)\n    labels  = add_cluster_feature(mm_train_df,1)\n    df['labels'] = labels\n    # # df = add_feature_curl(df)\n    # df = add_feature_area_minus_convex(df)\n    # df = add_feature_shapeFactor5(df)\n    # X,y = features_target(df,features)\n    # df = remove_outliers_zscore(X)\n    # df['y'] = y\n\n\n    # # df = log_transform(df,skewed_cols)\n    # # df = sqrt_transform(df,skewed_cols)\n    # df = boxcox_transform(df,skewed_cols)\n\n    # df = feature_boxcox_transform(df,skewed_cols)\n    # df = feature_log_transform(df,skewed_cols)\n    # df = feature_sqrt_transform(df,skewed_cols)\n\n    \n    return df\ndef pipline_test(df):\n    # df = float_of_column(df,float_cols)\n    labels  = add_cluster_feature(mm_test_df,1)\n    df['labels'] = labels\n    # # df = add_feature_curl(df)\n    # df = add_feature_area_minus_convex(df)\n    # df = add_feature_shapeFactor5(df)\n\n    # # df = log_transform(df,skewed_cols)\n    # # df = sqrt_transform(df,skewed_cols)\n    # df = boxcox_transform(df,skewed_cols)\n    # df = feature_boxcox_transform(df,skewed_cols)\n    # df = feature_log_transform(df,skewed_cols)\n    # df = feature_sqrt_transform(df,skewed_cols)    \n\n\n    return df\n\n\n\ntrain = pipline_train(train);\ntest  = pipline_test(test);\n\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:52.766197Z","iopub.status.busy":"2021-09-14T08:19:52.765901Z","iopub.status.idle":"2021-09-14T08:19:53.036820Z","shell.execute_reply":"2021-09-14T08:19:53.035989Z","shell.execute_reply.started":"2021-09-14T08:19:52.766168Z"},"id":"QH_jQy6ldMLN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(ss_train_df['lablels'],y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_train_df['lablels'] =train['labels']\nss_test_df['lablels'] = test['labels']\n\nmm_train_df['lablels'] = train['labels']\nmm_test_df['lablels'] =  test['labels']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mm_train_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = mm_train_df.columns\nX,y = mm_train_df,y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sira_dermason = mm_train_df[(y == 'SIRA') | (y == 'DERMASON') ]\n# sira_dermason_model = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n#               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n#               hidden_layer_sizes=(100,50,), learning_rate='adaptive',\n#               learning_rate_init=0.001, max_fun=15000, max_iter=500,\n#               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n#               power_t=0.5, random_state=42, shuffle=True, solver='adam',\n#               tol=0.0001, validation_fraction=0.2, verbose=False,\n#               warm_start=False)\n# sira_dermason_model = SVC()\nsira_dermason_model = ctb.CatBoostClassifier(random_state = 42, verbose=0,thread_count=-1)\n# sira_dermason_model = KNeighborsClassifier(n_neighbors=20)\n# sira_dermason_model = xgb.XGBClassifier(random_state = 42, verbosity=0)\nX_sira_dermason,y_sira_dermason = sira_dermason, y[(y == 'SIRA') | (y == 'DERMASON') ]\n# xtrain,xvalid,ytrain,yvalid = train_test_split(X,y,random_state=42,test_size=0.2)\n# sira_dermason_model.fit(xtrain,ytrain)\n# preds = sira_dermason_model.predict(xtrain)\n# preds2 = sira_dermason_model.predict(xvalid)\n# print(\"accuracy is {}\".format(accuracy_score(ytrain,preds)))\n# print(\"accuracy is {}\".format(accuracy_score(yvalid,preds2)))\n\n\n\nkf = KFold(n_splits=5,random_state=1,shuffle=True)\ni=1\n# scores=[]\nfor train_index, test_index in kf.split(X_sira_dermason,y_sira_dermason):\n#         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_train, X_test = X_sira_dermason.iloc[train_index], X_sira_dermason.iloc[test_index]\n        y_train, y_test = y_sira_dermason.iloc[train_index], y_sira_dermason.iloc[test_index]\n        # for model in models:\n        sira_dermason_model.fit(X_train,y_train)\n        \n        preds_train = sira_dermason_model.predict(X_train)        \n        preds_test = sira_dermason_model.predict(X_test)\n        print(\"fold {}  train accuracy is {}\".format(i,accuracy_score(y_train,preds_train)))\n                        \n        print(\"fold {}  test accuracy is {}\".format(i,accuracy_score(y_test,preds_test)))\n\n        # scores.append(accuracy_score(y_test,preds_test))\n        i+=1\n# fold 1  train accuracy is 0.9236602628918099\n# fold 1  test accuracy is 0.9171717171717172\n# fold 2  train accuracy is 0.9257012888551933\n# fold 2  test accuracy is 0.9191102123356926\n# fold 3  train accuracy is 0.931008339651251\n# fold 3  test accuracy is 0.9049544994944388\n# fold 4  train accuracy is 0.9226686884003032\n# fold 4  test accuracy is 0.9251769464105156\n# fold 5  train accuracy is 0.9206469547637098\n# fold 5  test accuracy is 0.9322548028311426\n\nsira_dermason_model.fit(X_sira_dermason,y_sira_dermason)","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:19:57.745631Z","iopub.status.busy":"2021-09-14T08:19:57.745368Z","iopub.status.idle":"2021-09-14T08:20:02.418282Z","shell.execute_reply":"2021-09-14T08:20:02.417335Z","shell.execute_reply.started":"2021-09-14T08:19:57.745605Z"},"id":"j6XzfqAddMLP","outputId":"5ff04a09-897d-44c6-aff8-c2c081b7f746"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = ctb.CatBoostClassifier(random_state = 42, verbose=0,thread_count=-1)\n# model = K\nmodel = xgb.XGBClassifier(random_state = 42, verbosity=0,n_jobs=-1)\n# model = SVC()\nX,y = mm_train_df,y\n# model = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n#               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n#               hidden_layer_sizes=(200,), learning_rate='adaptive',\n#               learning_rate_init=0.001, max_fun=15000, max_iter=500,\n#               momentum=0.8, n_iter_no_change=10, nesterovs_momentum=True,\n#               power_t=0.5, random_state=42, shuffle=True, solver='adam',\n#               tol=0.0001, validation_fraction=0.2, verbose=False,\n#               warm_start=False)\n# X,y = features_target(train,features)\nkf = KFold(n_splits=5,random_state=1,shuffle=True)\ni=1\n# scores=[]\nfor train_index, test_index in kf.split(X,y):\n#         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        # for model in models:\n        \n        model.fit(X_train,y_train)\n        preds_test = model.predict(X_test)\n\n#         cm = confusion_matrix(y_test,preds_test)\n#         ConfusionMatrixDisplay(cm,display_labels=y.unique()).plot()\n#         plt.xticks(rotation=90)\n\n        \n        mask = np.logical_or(preds_test=='SIRA',preds_test=='DERMASON')\n        X_test_sira_dermason = X_test[mask]\n\n\n        sira_dermason_updated_predictions = sira_dermason_model.predict(X_test_sira_dermason) \n        print(\"fold {} a test accuracy is {}\".format(i,accuracy_score(y_test,preds_test)))\n        preds_test[mask] = sira_dermason_updated_predictions\n#         unique, counts = np.unique(preds_test, return_counts=True)\n        # print (np.asarray((unique, counts)).T)\n        \n#         cm2 = confusion_matrix(y_test,preds_test)\n#         ConfusionMatrixDisplay(cm2,display_labels=y.unique()).plot()\n#         plt.xticks(rotation=90)\n#         plt.show()               \n        print(\"fold {} a test accuracy is {}\".format(i,accuracy_score(y_test,preds_test)))\n\n        i+=1\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:20:26.042258Z","iopub.status.busy":"2021-09-14T08:20:26.041994Z","iopub.status.idle":"2021-09-14T08:22:05.733739Z","shell.execute_reply":"2021-09-14T08:22:05.733190Z","shell.execute_reply.started":"2021-09-14T08:20:26.042233Z"},"id":"kcfdp0cqdMLS","outputId":"3343ef1f-48a6-48b3-d62c-7bda7f47378a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n\n    tree_method = ['exact','approx','hist']\n    boosting_list = ['gblinear','gbtree']\n\n#     feature_selector_list = ['cyclic','shuffle','random','greedy','thrifty']\n#     param ={\n# #           'n_estimators':trial.suggest_int('n_estimators', 30,300),\n# #           'max_depth':trial.suggest_int('max_depth',1,16),\n# #           'reg_lambda':trial.suggest_int('reg_lambda', 1,15),\n#          \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n#         \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n#         'iterations':trial.suggest_int('iterations', 50,700),\n#         'learning_rate':trial.suggest_uniform(\"learning_rate\", 0.01, 0.3),\n#         'random_strength':trial.suggest_int(\"random_strength\", 1,10),\n# #         'max_bin':trial.suggest_categorical('max_bin', [2,3,4,5,6,8,10,20,30]),\n# #         'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),        \n#         \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.1, 1),\n#         'od_type' : \"Iter\",\n#         'od_wait' : 30,\n#         \"depth\": trial.suggest_int(\"max_depth\", 2,7),\n#         \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 1, 10),\n# #          'task_type' : 'GPU'\n#         \"thread_count\": -1\n#       }\n    param = {\n        \"verbosity\": 0,\n        'n_estimators':trial.suggest_int('n_estimators', 30,300),\n        'max_depth':trial.suggest_int('max_depth',4,50),\n\n        # use exact for small dataset.\n        \"tree_method\": trial.suggest_categorical(\"tree_method\", ['exact','approx','hist']),\n        # defines booster, gblinear for linear functions.\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n        # L2 regularization weight.\n        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n        # L1 regularization weight.\n        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n        # sampling ratio for training data.\n        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n        # sampling according to each tree.\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n        'learning_rate':trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n\n    }\n\n    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n        # maximum depth of the tree, signifies complexity of the tree.\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n        # minimum child weight, larger the term more conservative the tree.\n        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n        # defines how selective algorithm is.\n        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n\n    if param[\"booster\"] == \"dart\":\n        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n\n    model = xgb.XGBClassifier(random_state = 42, verbose= 0,**param)  \n\n    i=1\n    scores=[]\n    for train_index, test_index in kf.split(X,y):\n            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n            model.fit(X_train,y_train)\n#             preds_train = model.predict(X_train)\n            preds_test = model.predict(X_test)\n\n            mask = np.logical_or(preds_test=='SIRA',preds_test=='DERMASON')\n            X_test_sira_dermason = X_test[mask]\n            sira_dermason_updated_predictions = sira_dermason_model.predict(X_test_sira_dermason) \n            \n            preds_test[mask] = sira_dermason_updated_predictions\n            scores.append(accuracy_score(y_test,preds_test))\n            i+=1\n            preds_test[mask] = sira_dermason_updated_predictions\n            # unique, counts = np.unique(preds_test, return_counts=True)\n            # print (np.asarray((unique, counts)).T)\n    avg_acc  = np.mean(scores)\n    print(\"avg test accuracy is {}\".format(avg_acc))\n\n    return avg_acc\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"id":"yLkYDQlSdMLU","outputId":"014692cc-f55f-40f5-ab2f-b18c6c8b7bdb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndef get_current_date_time():\n    now = datetime.now()\n    dt_string = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n    return dt_string\n\n    \n\ndef generate_submission(ID,preds,model_name,acurracy):\n    current_date_time = get_current_date_time()\n    file_name = model_name+\"_\"+str(acurracy)+\"_\"+current_date_time+\".csv\"\n    file_path = r'../submissions/'\n    submission = pd.DataFrame({\"ID\":ID, \"y\":preds})\n    print(file_path+file_name)\n    submission.to_csv(os.path.join(file_path,file_name), index=False)\n    print(submission.shape)\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:25:51.047862Z","iopub.status.busy":"2021-09-14T08:25:51.047543Z","iopub.status.idle":"2021-09-14T08:25:51.054692Z","shell.execute_reply":"2021-09-14T08:25:51.053795Z","shell.execute_reply.started":"2021-09-14T08:25:51.047817Z"},"id":"eqrK_N8TdMLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # param = {'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'iterations': 655,\n# #           'learning_rate': 0.15802933328209717, 'random_strength': 10,\n# #           'colsample_bylevel': 0.7201309776121098, 'max_depth': 4, 'l2_leaf_reg': 6}\n\n# param = {'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'iterations': 560,\n#  'learning_rate': 0.2999043265116359, 'random_strength': 4, \n#  'colsample_bylevel': 0.7863645192866875, 'max_depth': 2, 'l2_leaf_reg': 1}\nparam = {'n_estimators': 254, 'max_depth': 30, 'tree_method': 'approx',\n         'booster': 'dart', 'lambda': 3.6805271258795584e-06,\n         'alpha': 0.0017702781415986956, 'subsample': 0.5029439162420813,\n         'colsample_bytree': 0.711692717837368, 'learning_rate': 0.28897901718740016,\n         'min_child_weight': 2, 'eta': 1.2800474076575452e-05, 'gamma': 4.449002311878155e-06,\n         'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', \n         'rate_drop': 0.20997034391432784, 'skip_drop': 1.2586700209645195e-08}\n# X,y = features_target(train,features)\n# model2 = SVC()   \nmodel2= xgb.XGBClassifier(random_state = 42, verbosity= 0, **param)  \nmodel2.fit(X,y)\n\n\ntest = mm_test_df[features]\nout = model2.predict(test)\n\nunique, counts = np.unique(out, return_counts=True)\nprint (np.asarray((unique, counts)).T)\n\n\nmask = np.logical_or(out=='SIRA',out=='DERMASON')\nX_test_sira_dermason = test[mask]\n\n\nsira_dermason = train[(y == 'SIRA') | (y == 'DERMASON') ]\n# sira_dermason_model = ctb.CatBoostClassifier(random_state = 42, verbose=0,thread_count=-1)\n# X_sira_dermason,y_sira_dermason = features_target(sira_dermason,features)\nsira_dermason_model.fit(X_sira_dermason,y_sira_dermason)\nsira_dermason_updated_predictions = sira_dermason_model.predict(X_test_sira_dermason)\n\n\nout[mask] = sira_dermason_updated_predictions\nunique, counts = np.unique(out, return_counts=True)\nprint (np.asarray((unique, counts)).T)\n\n# study.best_value\n","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:51:50.371242Z","iopub.status.busy":"2021-09-14T08:51:50.370407Z","iopub.status.idle":"2021-09-14T08:52:19.498190Z","shell.execute_reply":"2021-09-14T08:52:19.497291Z","shell.execute_reply.started":"2021-09-14T08:51:50.371198Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pd.read_csv('a.csv')\na = a.y\na.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['ID'].shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name='mix'\nacc = 0.1\ngenerate_submission(ids,out.reshape(-1,),model_name,acc)","metadata":{"execution":{"iopub.execute_input":"2021-09-14T08:53:28.471802Z","iopub.status.busy":"2021-09-14T08:53:28.471535Z","iopub.status.idle":"2021-09-14T08:53:28.485768Z","shell.execute_reply":"2021-09-14T08:53:28.485154Z","shell.execute_reply.started":"2021-09-14T08:53:28.471767Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}